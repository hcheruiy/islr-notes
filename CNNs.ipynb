{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9BJuEch3KNehAwL6NnV29"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co3i0l7Zzqyz",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks (CNNs)\n",
        "\n",
        "The figure below shows the CNN model for the MNIST digit classification. Instead of having input vector like MLP, the input tensor now has new dimensions (`height`, `width`, `channels`) or `(image_size, image_size, 1) = (28, 28, 1)` for the grayscale MNIST images. Resizing the train and test images will be needed to conform to this input shape requirement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3f4BNUvznDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "6c29998a-0448-47cc-91c1-ccd1ddc73c60"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "# import libraries\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# load mnist dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# compute the number of labels\n",
        "num_labels = len(np.unique(y_train))\n",
        "\n",
        "# convert to one-hot vector\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# input image dimensions\n",
        "image_size = X_train.shape[1]\n",
        "\n",
        "# resize and normalize\n",
        "X_train = np.reshape(X_train,[-1, image_size, image_size, 1])\n",
        "X_test = np.reshape(X_test,[-1, image_size, image_size, 1])\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# network parameters\n",
        "# image is processed as is (square grayscale)\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "pool_size = 2\n",
        "filters = 64\n",
        "dropout = 0.2\n",
        "\n",
        "# model is a stack of CNN-ReLU-MaxPooling\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "# dropout added as regularizer\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "# output layer is 10-dim one-hot vector\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "plot_model(model, to_file='cnn-mnist.png', show_shapes=True)\n",
        "\n",
        "# loss function for one-hot vector\n",
        "# use of adam optimizer\n",
        "# accuracy is good metric for classification tasks\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the network\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=batch_size)\n",
        "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                5770      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 80,266\n",
            "Trainable params: 80,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.2533 - accuracy: 0.9233\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0673 - accuracy: 0.9789\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0480 - accuracy: 0.9852\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0383 - accuracy: 0.9880\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0331 - accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0276 - accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0238 - accuracy: 0.9920\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0215 - accuracy: 0.9934\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0183 - accuracy: 0.9940\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0162 - accuracy: 0.9951\n",
            "10000/10000 [==============================] - 0s 39us/sample - loss: 0.0301 - accuracy: 0.9894\n",
            "\n",
            "Test accuracy: 98.9%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeLrsWMg4Ip9",
        "colab_type": "text"
      },
      "source": [
        "The major change here is the use of `Conv2D` layers. The `relu` activation function is already an argument of `Conv2D`. The `relu` function can be brought out as an `Activation` layer when the __batch normalization__ layer is included in the model. Batch normalization is used in deep CNNs so that large learning rates can be used without causing instability during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol8s0MXf4WDb",
        "colab_type": "text"
      },
      "source": [
        "## Convolution\n",
        "\n",
        "If in the MLP model the number of units characterizes the `Dense` layers, the kernel characterizes the CNN operations. As shown in the figure below, the kernel can be visualized as a rectangular patch or window that slides through the whole image from left to right, and top to bottom. This operation is called __convolution__. It transforms the input image into a __feature maps__, which is a representation of what the kernel has _learned_ from the input image. The feature maps are then transformed into another feature maps in the succeeding layer and so on. The number of feature maps generated per `Conv2D` is controlled by the `filters` argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LFDGwER5AJN",
        "colab_type": "text"
      },
      "source": [
        "## Pooling Operations\n",
        "\n",
        "The last change is the addition of a `MaxPooling2D` layer with the argument `pool_size=2`. `MaxPooling2D` compresses each feature map. Every patch of size `pool_size × pool_size` is reduced to one pixel. The value is equal to the maximum pixel value within the patch. `MaxPooling2D` is shown in the following figure for two patches:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APkudS065fhi",
        "colab_type": "text"
      },
      "source": [
        "The significance of `MaxPooling2D` is the reduction in feature maps size which translates to increased kernel coverage. For example, after `MaxPooling2D(2)`, the 2 × 2 kernel is now approximately convolving with a 4 × 4 patch. The CNN has learned a new set of feature maps for a different coverage.\n",
        "\n",
        "There are other means of pooling and compression. For example, to achieve a 50% size reduction as `MaxPooling2D(2), AveragePooling2D(2)` takes the average of a patch instead of finding the maximum. Strided convolution, `Conv2D(strides=2, ...)` will skip every two pixels during convolution and will still have the same 50% size reduction effect. There are subtle differences in the effectiveness of each reduction technique.\n",
        "\n",
        "In `Conv2D` and `MaxPooling2D`, both `pool_size` and `kernel` can be non-square. In these cases, both the row and column sizes must be indicated. For example, `pool_size=(1, 2)` and `kernel=(3, 5)`.\n",
        "\n",
        "The output of the last `MaxPooling2D` is a stack of feature maps. The role of `Flatten` is to convert the stack of feature maps into a vector format that is suitable for either `Dropout` or `Dense` layers, similar to the MLP model output layer."
      ]
    }
  ]
}